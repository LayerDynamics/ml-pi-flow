version: "3.8"

services:
  reverse_proxy:
    image: nginx:alpine
    container_name: nginx_proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/certs:/etc/letsencrypt:ro
      - ./nginx/html:/usr/share/nginx/html
    environment:
      - DOMAIN=${DOMAIN:-example.com}
    depends_on:
      - dashboard
      - web_portal
    restart: unless-stopped

  certbot:
    image: certbot/certbot
    container_name: certbot
    volumes:
      - ./nginx/certs:/etc/letsencrypt
      - ./nginx/html:/usr/share/nginx/html
    entrypoint: >
      certbot certonly --webroot
      --webroot-path=/usr/share/nginx/html
      --email ${CERTBOT_EMAIL}
      --agree-tos
      --no-eff-email
      -d ${DOMAIN}
    restart: "no"

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    ports:
      - "5000:5000"
    volumes:
      - mlflow_data:/mlflow
    environment:
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  tensorboard:
    image: tensorflow/tensorflow:2.15.0
    container_name: tensorboard
    ports:
      - "6006:6006"
    volumes:
      - tensorboard_logs:/logs
    command: >
      tensorboard
      --logdir=/logs
      --host=0.0.0.0
      --port=6006
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6006"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  vector_db:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chroma
    ports:
      - "8000:8000"
    volumes:
      - chroma_data:/data
    environment:
      - IS_PERSISTENT=true
      - PERSIST_DIRECTORY=/data
    restart: unless-stopped

  label_studio:
    image: heartexlabs/label-studio:latest
    container_name: label_studio
    ports:
      - "${LABEL_STUDIO_PORT}:${LABEL_STUDIO_PORT}"
    volumes:
      - label_studio_data:/label-studio/data
    environment:
      - LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=${LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED}
      - LABEL_STUDIO_HOST=${LABEL_STUDIO_HOST}
      - LABEL_STUDIO_PORT=${LABEL_STUDIO_PORT}
      - LABEL_STUDIO_API_KEY=${LABEL_STUDIO_API_KEY}
    user: "1000:1000"
    command: >
      label-studio start
      --port ${LABEL_STUDIO_PORT}
      --host ${LABEL_STUDIO_HOST}
    restart: unless-stopped

  great_expectations:
    build:
      context: ./great_expectations
      dockerfile: Dockerfile
    container_name: great_expectations
    ports:
      - "4000:4000"
    volumes:
      - great_expectations_data:/app/great_expectations
    working_dir: /app/great_expectations
    command: >
      /bin/bash -c "
      great_expectations docs build &&
      cd uncommitted/data_docs/local_site &&
      python3 -m http.server 4000 --bind 0.0.0.0
      "
    restart: unless-stopped

  dashboard:
    container_name: dashboard
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    ports:
      - "9000:9000"
    volumes:
      - ./dashboard:/app
    command: streamlit run app.py --server.port=9000 --server.address=0.0.0.0
    restart: unless-stopped

  web_portal:
    container_name: web_portal
    build:
      context: ./web_portal
      dockerfile: Dockerfile
    ports:
      - "9090:9090"
    volumes:
      - ./web_portal:/app
    command: uvicorn main:app --host 0.0.0.0 --port 9090
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  mlflow_data:
  tensorboard_logs:
  chroma_data:
  label_studio_data:
  great_expectations_data:

networks:
  default:
    driver: bridge
